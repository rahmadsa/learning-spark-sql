{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyrKOfUTGRYT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**D. Exploratory Data Analysis dengan Apache Spark**\n",
        "\n",
        "\n",
        "##**Bagian 1**\n",
        "\n",
        "##**1. Hadoop & PySpark initialization di Google Colab**\n",
        "\n",
        "*PySpark* adalah *interface Python* untuk *Apache Spark*. Penggunaan utama *PySpark* adalah untuk bekerja dengan data dalam Bigdata dan untuk membuat pipeline data.\n",
        "\n",
        "Walaupun *Apache Spark* mendudukung Big Data, sebagai awal pembelajaran tidak perlu menggunakan data yang besar untuk mendapatkan manfaat dari PySpark. Kita bisa temukan bahwa SparkSQL adalah tools yang bagus untuk melakukan analisis data. Penggunaan library Panda menjadi lambat dengan data yang besar Sumber tentang Apache Spark http://spark.apache.org/docs/latest/api/python/\n",
        "\n"
      ],
      "metadata": {
        "id": "Gun9kIlx5fJb"
      }
    }
  ]
}